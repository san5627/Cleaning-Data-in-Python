# Ensuring all categorical variables in a DataFrame which are of type category because it reduces memory usage.
# Convert the sex column to type 'category'
tips.sex = tips.sex.astype('category')

# Convert the smoker column to type 'category'
tips.smoker = tips.smoker.astype('category')

# Print the memory usage of tips after converting the data types of the columns.
# Use the .info() method to do this.
# Print the info of tips
print(tips.info())

# Use pd.to_numeric() to convert the 'total_bill' column of tips to a numeric data type.
# Coerce the errors to NaN by specifying the keyword argument errors='coerce'.
# Convert 'total_bill' to a numeric dtype
tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')

# Convert 'tip' to a numeric dtype
tips['tip'] = pd.to_numeric(tips['tip'], errors='coerce')

# Print the info of tips
print(tips.info())

# When working with data, it is sometimes necessary to write a regular expression to look for properly entered values. 
# The regular expression module in python is re.
# When performing pattern matching on data, since the pattern will be used for a match across multiple rows,
# it's better to compile the pattern first using re.compile(), and then use the compiled pattern to match values.

# Import the regular expression module
import re

# Compile the pattern: prog
prog = re.compile('\d{3}-\d{3}-\d{4}')

# See if the pattern matches
result = prog.match('123-456-7890')
print(bool(result))  # True

# See if the pattern matches
result2 = prog.match('1123-456-7890')
print(bool(result2))  # False

# When using a regular expression to extract multiple numbers (or multiple pattern matches, to be exact),
# you can use the re.findall() function
# but it is straightforward to use: You pass in a pattern and a string to re.findall(), and it will return a list of the matches.

# Import the regular expression module
import re

# Find the numeric values: matches
matches = re.findall('\d+', 'the recipe calls for 10 strawberries and 1 banana')

# Print the matches
print(matches)  # ['10','1']

# Write the first pattern
pattern1 = bool(re.match(pattern='\d{3}-\d{3}-\d{4}', string='123-456-7890'))
print(pattern1)  # True

# A string of the format: A dollar sign, an arbitrary number of digits, a decimal point, 2 digits.
# Use \$ to match the dollar sign
# \d* to match an arbitrary number of digits
# \. to match the decimal point
# and \d{x} to match x number of digits.
# Write the second pattern
pattern2 = bool(re.match(pattern='\$\d*\.\d{2}', string='$123.45'))
print(pattern2)  #True

# Use [A-Z] to match any capital letter
# followed by \w* to match an arbitrary number of alphanumeric characters
# Write the third pattern
pattern3 = bool(re.match(pattern='[A-Z]\w*', string='Australia'))
print(pattern3)  # True


# Define recode_gender()
def recode_gender(gender):

    # Return 0 if gender is 'Female'
    if gender == 'Female':
        return 0
    
    # Return 1 if gender is 'Male'
    elif gender == 'Male':
        return 1
        
    # Return np.nan    
    else:
        return np.nan

# Apply the function to the sex column
tips['recode'] = tips.sex.apply(recode_gender)

# Print the first five rows of tips
print(tips.head())

# Difference between two columns
import re
from numpy import Nan
pattern = re.compile('^\$\d*\.\d{2}$')

def diff_money(row, pattern):
 icost = row['Initial Cost']
 tef = row['Total Est. Fee']

 if bool(pattern.match(icost)) and bool(pattern.match(tef)):
 icost = icost.replace("$", "")
 tef = tef.replace("$", "")

 icost = float(icost)
 tef = float(tef)

 return icost - tef
 else:
 return(NaN)

df['diff'] = df.apply(diff_money, axis=1, pattern=pattern)

# Lamda Functions - Powerful Python feature that will help you clean your data more effectively: lambda functions.
# For example, here's a function that squares a variable used in an .apply() method:

def my_square(x):
    return x ** 2

df.apply(my_square)

# The equivalent code using a lambda function is:

df.apply(lambda x: x ** 2)

# The lambda function takes one parameter - the variable x.
# The function itself just squares x and returns the result, which is whatever the one line of code evaluates to.

# Write the lambda function using replace
tips['total_dollar_replace'] = tips.total_dollar.apply(lambda x: x.replace('$', ''))

# Write the lambda function using regular expressions
tips['total_dollar_re'] = tips.total_dollar.apply(lambda x: re.findall('\d+\.\d+', x)[0])


# Dropping duplicate data
# Duplicate data causes a variety of problems.
# From the point of view of performance, they use up unnecessary amounts of memory and cause unneeded calculations to be performed when processing data.
# In addition, they can also bias any analysis results.

# Create the new DataFrame: tracks
tracks = billboard[['year', 'artist', 'track', 'time']]

# Print info of tracks
print(tracks.info())

# Drop the duplicates: tracks_no_duplicates
tracks_no_duplicates = tracks.drop_duplicates()

# Print info of tracks
print(tracks_no_duplicates.info())


# Replacing missing values with the mean value
# Calculate the mean of the Ozone column: oz_mean
oz_mean = airquality['Ozone'].mean()

# Replace all the missing values in the Ozone column with the mean
airquality['Ozone'] = airquality['Ozone'].fillna(oz_mean)

# Print the info of airquality
print(airquality.info())


# Testing your data with asserts
# Assert that there are no missing values
assert pd.notnull(ebola).all().all()

# Assert that all values are >= 0
assert (ebola >= 0).all().all()
